# What is Big data

This is data science + ML; ML is necessary to analyze
In the end you'll have 2 softwares/utilities

Pre TO DO:

- Do a NN (First task)
- An analysis with big amount of data (Nothing to code here) -> *USE A BIG DATA SET I MEAN BIG 50k is enough*

Big data is about 25TB, if you can storage it; that's not big data (Remember, this computer owns 1TB)

_A goal of big data analytics is to reduce costs_

## So what the is big data

A way to analyze data, the quantity of data is not your matter (But if you can store it that's not big data)

| Narrow                | Issue                          |
| --------------------- | ------------------------------ |
| Size (TB)             | Volume of the data            |
| Velocity              | Update frequency               |
| Structure of the data | Artificial Intelligence        |
| Security              | Integrity                      |
| Topology              | It can increase the complexity |

> Updating a problem to predict behavior derivate into a Big data problem

The idea is to use data to convert then into goal, insights

### Consideration about Big data

- It requires more data to improve the accuracy of generated predictions
- Historical data -> Give a view but can't be give you the best predictions (When we are talking about people)
- You need to use some other metrics as stochastic analysis (Scenarios, even the impossible once or future scenarios) or probabilistic analysis
- Storage *usually the first issue* -> When you are planning to handle with a big amount of data, *you need to keep the data correctly*, using *servers, cloud or an external company*

### Consideration for big data problems

- Analyze the target, get involve in the area, choose rightly the target. To be clear and know about the area of interest is required to select the target or goal
- To know the technical, physical, operational limits and so on of the problem
- Be able to custom you vars, you need to handle with a great amount of variables
- Identify the *decision variables* (According to the problem)
- Analyze the initial data with data mining
- To use data visualization to find insights and correlations
- High and low impact characteristics. Those characteristics hit the initial 
- Limit and control the entries in the data base since the beginning

> Spent time in the initial analysis 

> Usually as a software dev; generally we are improving or creating things

> MINIMUM 100 years is "ok" for historical to find patterns

#### Software to use

[Apache Hadoop](https://hadoop.apache.org/)
[Scikit-learn](https://scikit-learn.org/stable/)

###### Software might be useful

[DVC](https://dvc.org/doc)
[Kaggle](https://www.kaggle.com/)

> Here we use Free Software

#### Tip

- Enroll an statistic course before enjoying the big-data